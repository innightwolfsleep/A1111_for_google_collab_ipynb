{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfTtk/AGWStuoNE0sQJbZ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/innightwolfsleep/A1111_for_google_collab_ipynb/blob/main/llm_telegram_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FeDjZxu5_Zon",
        "outputId": "b915f206-33fd-49b9-f586-5fc7156f53cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting APScheduler==3.6.3 (from python-telegram-bot==13.15->-r /content/llm_telegram_bot/requirements_ext.txt (line 1))\n",
            "  Downloading APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.15->-r /content/llm_telegram_bot/requirements_ext.txt (line 1)) (2023.3.post1)\n",
            "Collecting cachetools==4.2.2 (from python-telegram-bot==13.15->-r /content/llm_telegram_bot/requirements_ext.txt (line 1))\n",
            "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf==2.3.0->-r /content/llm_telegram_bot/requirements_ext.txt (line 4))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.9.0->-r /content/llm_telegram_bot/requirements_ext.txt (line 12)) (4.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.15->-r /content/llm_telegram_bot/requirements_ext.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.15->-r /content/llm_telegram_bot/requirements_ext.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.15->-r /content/llm_telegram_bot/requirements_ext.txt (line 1)) (5.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator>=1.9.2->-r /content/llm_telegram_bot/requirements_ext.txt (line 3)) (4.11.2)\n",
            "Collecting docopt>=0.6.2 (from num2words>=0.5.12->-r /content/llm_telegram_bot/requirements_ext.txt (line 5))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r /content/llm_telegram_bot/requirements_ext.txt (line 7)) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r /content/llm_telegram_bot/requirements_ext.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r /content/llm_telegram_bot/requirements_ext.txt (line 7)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r /content/llm_telegram_bot/requirements_ext.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->-r /content/llm_telegram_bot/requirements_ext.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.1->-r /content/llm_telegram_bot/requirements_ext.txt (line 7)) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2.0.1->-r /content/llm_telegram_bot/requirements_ext.txt (line 7)) (17.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->-r /content/llm_telegram_bot/requirements_ext.txt (line 9)) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->-r /content/llm_telegram_bot/requirements_ext.txt (line 9)) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator>=1.9.2->-r /content/llm_telegram_bot/requirements_ext.txt (line 3)) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->-r /content/llm_telegram_bot/requirements_ext.txt (line 7)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->-r /content/llm_telegram_bot/requirements_ext.txt (line 7)) (1.3.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, tornado, docopt\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=b5b493d810c45840a9763efe43bd01023cc945e5678c7eb5120b83e2ee8d7d61\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.1-cp310-cp310-linux_x86_64.whl size=421977 sha256=d15b74a878c02bd80868896c13111918fd4aa5aff767541b4114aca5a2298727\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/32/8d/21cf0fa6ee4e083f6530e5b83dfdfa9489a3890d320803f4c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=a02517c3ca6b285fa9dd0373953c03a884e13cc127da4fffcd39aef1cb46cd07\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built antlr4-python3-runtime tornado docopt\n",
            "Installing collected packages: docopt, antlr4-python3-runtime, tornado, python-dotenv, pydantic, Pillow, omegaconf, num2words, cachetools, backoff, APScheduler, python-telegram-bot, deep-translator\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.3.2\n",
            "    Uninstalling tornado-6.3.2:\n",
            "      Successfully uninstalled tornado-6.3.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.1\n",
            "    Uninstalling cachetools-5.3.1:\n",
            "      Successfully uninstalled cachetools-5.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires tornado==6.3.2, but you have tornado 6.1 which is incompatible.\n",
            "inflect 7.0.0 requires pydantic>=1.9.1, but you have pydantic 1.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed APScheduler-3.6.3 Pillow-10.0.1 antlr4-python3-runtime-4.9.3 backoff-2.2.1 cachetools-4.2.2 deep-translator-1.11.4 docopt-0.6.2 num2words-0.5.12 omegaconf-2.3.0 pydantic-1.9.0 python-dotenv-1.0.0 python-telegram-bot-13.15 tornado-6.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.11.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.11-cp310-cp310-manylinux_2_35_x86_64.whl size=1023481 sha256=eb50ef4ca30546811d6859799dd67ab10538be0fbc7894b6a7ab2cc87419307e\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/42/77/a3ab0d02700427ea364de5797786c0272779dce795f62c3bc2\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.11\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Start downloading model: collectivecognition-v1-mistral-7b.Q4_K_M.gguf\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/innightwolfsleep/llm_telegram_bot\n",
        "!pip install -r /content/llm_telegram_bot/requirements_ext.txt\n",
        "!pip install llama-cpp-python\n",
        "!pip install -q wget\n",
        "import wget\n",
        "import os\n",
        "def load_sd_model(url,):\n",
        "  if not os.path.exists(\"/content/llm_telegram_bot/models/\" + url.split(\"/\")[-1]):\n",
        "    print(\"Start downloading model: \" + url.split(\"/\")[-1])\n",
        "    wget.download(url, \"/content/llm_telegram_bot/models/\" + url.split(\"/\")[-1])\n",
        "    print(\"Download completed: \" + url.split(\"/\")[-1])\n",
        "  else:\n",
        "    print(\"Already downloaded model: \" + url.split(\"/\")[-1])\n",
        "\n",
        "load_sd_model(\"https://huggingface.co/TheBloke/CollectiveCognition-v1-Mistral-7B-GGUF/resolve/main/collectivecognition-v1-mistral-7b.Q4_K_M.gguf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rAkiqKskFMI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python llm_telegram_bot/run.py"
      ],
      "metadata": {
        "id": "3VGvBT3c_-3S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}